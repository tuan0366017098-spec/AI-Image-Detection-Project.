import torch
import os
import sys

def test_model():
    print("ğŸ§  AI Image Detector - Model Testing")
    print("=" * 50)
    
    # ThÃªm thÆ° má»¥c hiá»‡n táº¡i vÃ o path Ä‘á»ƒ import
    sys.path.append(os.path.dirname(__file__))
    
    try:
        from model_loader import load_model, predict_ai_image
        
        print("\n1. Testing model loading...")
        
        # Kiá»ƒm tra cÃ¡c file model cÃ³ thá»ƒ
        model_files = []
        possible_paths = [
            "models/model_best.pth",
            "models/ai_real_classifier.h5",
            "../Training-models/src/checkpoints/model_best.pth"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                model_files.append(path)
                print(f"   âœ… Found: {path}")
            else:
                print(f"   âŒ Not found: {path}")
        
        if model_files:
            model_path = model_files[0]
            print(f"   ğŸ”„ Loading model from: {model_path}")
        else:
            model_path = None
            print("   âš ï¸  No model files found, using dummy model")
        
        # Load model
        model = load_model(model_path)
        print(f"   âœ… Model loaded: {model is not None}")
        
        print("\n2. Testing model prediction...")
        
        # Táº¡o áº£nh test
        try:
            from PIL import Image
            import io
            import numpy as np
            
            # Táº¡o áº£nh RGB ngáº«u nhiÃªn
            dummy_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
            test_image = Image.fromarray(dummy_image)
            
            # Chuyá»ƒn thÃ nh bytes
            img_bytes = io.BytesIO()
            test_image.save(img_bytes, format='JPEG')
            img_bytes = img_bytes.getvalue()
            
            print("   ğŸ“· Created test image")
            
            # Test prediction
            result = predict_ai_image(img_bytes)
            
            if "error" in result:
                print(f"   âŒ Prediction error: {result['error']}")
            else:
                print(f"   âœ… Prediction successful!")
                print(f"   ğŸ¯ Result: {result['label']}")
                print(f"   ğŸ“Š Confidence: {result['confidence_score']:.4f}")
                print(f"   ğŸ¤– AI Generated: {result['is_ai_generated']}")
                print(f"   ğŸ“ˆ Raw Probability: {result.get('raw_probability', 'N/A')}")
                
        except ImportError as e:
            print(f"   âŒ Cannot create test image: {e}")
        except Exception as e:
            print(f"   âŒ Prediction test failed: {e}")
        
        print("\n3. Testing device information...")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"   ğŸ”§ Using device: {device}")
        if torch.cuda.is_available():
            print(f"   ğŸ® GPU: {torch.cuda.get_device_name(0)}")
            print(f"   ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        print("\nğŸ‰ Model Testing Completed!")
        if model_path:
            print(f"âœ… Model is working with: {os.path.basename(model_path)}")
        else:
            print("âœ… Dummy model is working (no real model file found)")
        
        return True
        
    except Exception as e:
        print(f"âŒ Model testing failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    if test_model():
        sys.exit(0)
    else:
        sys.exit(1)