import os
import torch
import torch.nn as nn
from torchvision import models, transforms
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import io
import logging
import uvicorn

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="AI Image Detector - REAL MODEL")

# CORS middleware (th√™m origin c·ªßa frontend b·∫°n n·∫øu c√≥)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

model = None
model_loaded = False

class RealAIModel:
    def __init__(self):
        self.model = None
        self.transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225])
    ])

        self.load_model()

    def load_model(self):
        global model_loaded
        model_path = "models/fast_model.pth"
        if not os.path.exists(model_path):
            logger.error(f"‚ùå Model file kh√¥ng t·ªìn t·∫°i: {model_path}")
            model_loaded = False
            return False

        logger.info(f"üîÑ ƒêang load model t·ª´: {model_path}")

        # Kh·ªüi t·∫°o model ResNet34 ƒë√∫ng c·∫•u tr√∫c
        self.model = models.resnet34(weights=None)
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, 2)  # 2 class: Real v√† AI

        checkpoint = torch.load(model_path, map_location='cpu')

        # Ki·ªÉm tra checkpoint d·∫°ng dict ho·∫∑c kh√¥ng
        if isinstance(checkpoint, dict):
            if "state_dict" in checkpoint:
                state_dict = checkpoint["state_dict"]
            elif "model_state_dict" in checkpoint:
                state_dict = checkpoint["model_state_dict"]
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint

        # Load state dict v·ªõi strict=False ƒë·ªÉ tr√°nh l·ªói mismatch key
        missing, unexpected = self.model.load_state_dict(state_dict, strict=False)

        if missing:
            logger.warning(f"‚ö† Missing keys khi load model: {missing}")
        if unexpected:
            logger.warning(f"‚ö† Unexpected keys khi load model: {unexpected}")

        self.model.eval()
        model_loaded = True
        logger.info("‚úÖ Model ƒë√£ load th√†nh c√¥ng")
        return True

    def predict(self, image_bytes):
        if not model_loaded or self.model is None:
            return {"error": "Model ch∆∞a ƒë∆∞·ª£c load"}

        try:
            image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0)  # Add batch dimension

            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)

                confidence, predicted = torch.max(probabilities, 1)

                is_ai = (predicted.item() == 1)
                confidence_score = confidence.item()

                # L·∫•y x√°c su·∫•t ri√™ng cho AI v√† Real
                ai_confidence = probabilities[0][1].item()
                real_confidence = probabilities[0][0].item()

            return {
                "is_ai_generated": is_ai,
                "confidence_score": round(confidence_score, 4),
                "label": "AI Generated" if is_ai else "Real Image",
                "class_index": predicted.item(),
                "ai_confidence": round(ai_confidence, 4),
                "real_confidence": round(real_confidence, 4),
            }
        except Exception as e:
            logger.error(f"‚ùå L·ªói d·ª± ƒëo√°n: {e}")
            return {"error": f"L·ªói x·ª≠ l√Ω ·∫£nh: {str(e)}"}


ai_model = RealAIModel()


@app.on_event("startup")
async def startup_event():
    logger.info("üöÄ Kh·ªüi ƒë·ªông backend v·ªõi MODEL TH·∫¨T...")
    if model_loaded:
        logger.info("üéØ S·∫¥N S√ÄNG NH·∫¨N ·∫¢NH V√Ä D·ª∞ ƒêO√ÅN")
    else:
        logger.error("‚ùå KH√îNG TH·ªÇ LOAD MODEL TH·∫¨T!")


@app.get("/")
def read_root():
    return {
        "message": "AI Image Detector - REAL MODEL",
        "model_loaded": model_loaded,
        "status": "ready" if model_loaded else "error"
    }


@app.get("/health")
def health_check():
    return {
        "status": "healthy" if model_loaded else "error",
        "model_loaded": model_loaded
    }


@app.post("/predict")
async def predict_image(file: UploadFile = File(...)):
    if not model_loaded:
        raise HTTPException(status_code=500, detail="Model ch∆∞a ƒë∆∞·ª£c load")

    if not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="File ph·∫£i l√† ·∫£nh")

    contents = await file.read()
    result = ai_model.predict(contents)

    if "error" in result:
        raise HTTPException(status_code=500, detail=result["error"])

    logger.info(f"üìä D·ª± ƒëo√°n: {result['label']} ({result['confidence_score']:.2%})")

    return {
        "is_ai_generated": result["is_ai_generated"],
        "confidence_score": result["confidence_score"],
        "label": result["label"],
        "ai_confidence": result["ai_confidence"],
        "real_confidence": result["real_confidence"],
        "filename": file.filename,
        "model_type": "REAL_MODEL"
    }


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
